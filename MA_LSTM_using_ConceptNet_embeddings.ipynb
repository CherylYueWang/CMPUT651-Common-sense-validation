{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6WVGu3tcUED4"
   },
   "outputs": [],
   "source": [
    "## Code adapted from https://github.com/likejazz/Siamese-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "DraaCOv9UUEX",
    "outputId": "c54daf5f-0302-426d-8da7-827677658241"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from time import time\n",
    "import matplotlib\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import gensim\n",
    "\n",
    "import itertools\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras.layers import Input, Embedding, LSTM, GRU, Conv1D, Conv2D, GlobalMaxPool1D, Dense, Dropout\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "ricXbZcHVf1D",
    "outputId": "80906687-f3a1-44ba-ea26-b9d2d002fc22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UtP5z5nGWod9"
   },
   "outputs": [],
   "source": [
    "#!wget https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "HvDSnqNq09rt",
    "outputId": "eb2fab4f-30df-4354-d407-24b134d0545c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-15 06:38:31--  https://conceptnet.s3.amazonaws.com/downloads/2019/numberbatch/numberbatch-en-19.08.txt.gz\n",
      "Resolving conceptnet.s3.amazonaws.com (conceptnet.s3.amazonaws.com)... 52.216.84.8\n",
      "Connecting to conceptnet.s3.amazonaws.com (conceptnet.s3.amazonaws.com)|52.216.84.8|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 325403502 (310M) [application/x-gzip]\n",
      "Saving to: ‘numberbatch-en-19.08.txt.gz’\n",
      "\n",
      "numberbatch-en-19.0 100%[===================>] 310.33M  16.4MB/s    in 21s     \n",
      "\n",
      "2019-12-15 06:38:52 (15.1 MB/s) - ‘numberbatch-en-19.08.txt.gz’ saved [325403502/325403502]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://conceptnet.s3.amazonaws.com/downloads/2019/numberbatch/numberbatch-en-19.08.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KAJ5s3sF2ae5"
   },
   "outputs": [],
   "source": [
    "!gunzip numberbatch-en-19.08.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CI3vrTxjXA5i",
    "outputId": "5409d09d-295b-494c-87d9-d24cf4821603"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numberbatch-en-19.08.txt  sample_data  train_masked_new.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZSHBoEq-TM2Q",
    "outputId": "7356c280-91bb-4781-dc64-0232189f2a32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsQKGYxaiJRq"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_masked_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "jmZ9Tg8fqH4P",
    "outputId": "e82f2300-7841-4f83-9254-5c263f4ab938"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>special</th>\n",
       "      <th>whole</th>\n",
       "      <th>label</th>\n",
       "      <th>masked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>orange juice</td>\n",
       "      <td>he pour orange juice on his cereal</td>\n",
       "      <td>0</td>\n",
       "      <td>he pour [MASK] on his cereal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>milk</td>\n",
       "      <td>he pour milk on his cereal</td>\n",
       "      <td>1</td>\n",
       "      <td>he pour [MASK] on his cereal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>he drink apple</td>\n",
       "      <td>0</td>\n",
       "      <td>he drink [MASK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>milk</td>\n",
       "      <td>he drink milk</td>\n",
       "      <td>1</td>\n",
       "      <td>he drink [MASK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>jeff run a mile today</td>\n",
       "      <td>1</td>\n",
       "      <td>jeff run [MASK] mile tod[MASK]y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  ... label                           masked\n",
       "0           0   0  ...     0     he pour [MASK] on his cereal\n",
       "1           1   0  ...     1     he pour [MASK] on his cereal\n",
       "2           2   1  ...     0                  he drink [MASK]\n",
       "3           3   1  ...     1                  he drink [MASK]\n",
       "4           4   2  ...     1  jeff run [MASK] mile tod[MASK]y\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "nde3TG4gUTzc",
    "outputId": "ad1cb8d8-8439-45ac-cd99-08dea77c08f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "# Stopwords\n",
    "stop_list = set(stopwords.words('english'))\n",
    "numberbatch = KeyedVectors.load_word2vec_format(\"/content/numberbatch-en-19.08.txt\", binary=False, unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "feVIg0xexi7c"
   },
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    return simple_preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "-BdnZ49cYjGj",
    "outputId": "8147f004-d23f-4411-bea2-be108e1af894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,000 sentences embedded.\n",
      "2,000 sentences embedded.\n",
      "3,000 sentences embedded.\n",
      "4,000 sentences embedded.\n",
      "5,000 sentences embedded.\n",
      "6,000 sentences embedded.\n",
      "7,000 sentences embedded.\n",
      "8,000 sentences embedded.\n",
      "9,000 sentences embedded.\n",
      "10,000 sentences embedded.\n",
      "11,000 sentences embedded.\n",
      "12,000 sentences embedded.\n",
      "13,000 sentences embedded.\n",
      "14,000 sentences embedded.\n",
      "15,000 sentences embedded.\n",
      "16,000 sentences embedded.\n",
      "17,000 sentences embedded.\n",
      "18,000 sentences embedded.\n",
      "19,000 sentences embedded.\n",
      "20,000 sentences embedded.\n",
      "21,000 sentences embedded.\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/content/train_masked_new.csv')\n",
    "train_df['whole_bow'] = train_df['whole']\n",
    "train_df['masked_bow'] = train_df['masked']\n",
    "\n",
    "word2id = {}\n",
    "id2word = {}\n",
    "word_idx = 0\n",
    "oov = {}\n",
    "\n",
    "# Make word2vec embeddings\n",
    "embedding_dim = 300\n",
    "max_seq_length = 20\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    if index != 0 and index % 1000 == 0:\n",
    "        print(\"{:,} sentences embedded.\".format(index), flush=True)\n",
    "\n",
    "    for col in ['whole_bow', 'masked_bow']:\n",
    "        bow = []  # bag of words of this sentence\n",
    "        for word in preprocess(row[col]):\n",
    "            # Check for unwanted words\n",
    "            if word in stop_list:\n",
    "                continue\n",
    "\n",
    "            # If a word is missing from word2vec model.\n",
    "            if word not in numberbatch.vocab:\n",
    "                if word not in oov:\n",
    "                    oov[word] = 1\n",
    "                else:\n",
    "                    oov[word] += 1\n",
    "                continue # simply ignore this word as it is OOV in our model\n",
    "\n",
    "            # put the word into vocab dictionary\n",
    "            if word not in word2id:\n",
    "                word_idx += 1\n",
    "                word2id[word] = word_idx\n",
    "                id2word[word_idx] = word\n",
    "                bow.append(word_idx)\n",
    "            else:\n",
    "                bow.append(word2id[word])\n",
    "\n",
    "        # Generate bag of words representation\n",
    "        train_df.at[index, col] = bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpeHUe7Lzgvb"
   },
   "outputs": [],
   "source": [
    "embeddings = 1 * np.random.randn(len(word2id) + 1, embedding_dim)  # This will be the embedding matrix\n",
    "embeddings[0] = 0  # So that the padding will be ignored\n",
    "\n",
    "# Build the embedding matrix\n",
    "for word, idx in word2id.items():\n",
    "    if word in numberbatch.vocab:\n",
    "        embeddings[idx] = numberbatch.word_vec(word) # retrieve numberbatch embeddings for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "FozyUJf8vddk",
    "outputId": "f22924f2-ec01-4671-b4be-06809b6c2b80"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>special</th>\n",
       "      <th>whole</th>\n",
       "      <th>label</th>\n",
       "      <th>masked</th>\n",
       "      <th>whole_bow</th>\n",
       "      <th>masked_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>orange juice</td>\n",
       "      <td>he pour orange juice on his cereal</td>\n",
       "      <td>0</td>\n",
       "      <td>he pour [MASK] on his cereal</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>[1, 5, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>milk</td>\n",
       "      <td>he pour milk on his cereal</td>\n",
       "      <td>1</td>\n",
       "      <td>he pour [MASK] on his cereal</td>\n",
       "      <td>[1, 6, 4]</td>\n",
       "      <td>[1, 5, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>he drink apple</td>\n",
       "      <td>0</td>\n",
       "      <td>he drink [MASK]</td>\n",
       "      <td>[7, 8]</td>\n",
       "      <td>[7, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>milk</td>\n",
       "      <td>he drink milk</td>\n",
       "      <td>1</td>\n",
       "      <td>he drink [MASK]</td>\n",
       "      <td>[7, 6]</td>\n",
       "      <td>[7, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>jeff run a mile today</td>\n",
       "      <td>1</td>\n",
       "      <td>jeff run [MASK] mile tod[MASK]y</td>\n",
       "      <td>[9, 10, 11, 12]</td>\n",
       "      <td>[9, 10, 5, 11, 13, 5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  ...        whole_bow             masked_bow\n",
       "0           0   0  ...     [1, 2, 3, 4]              [1, 5, 4]\n",
       "1           1   0  ...        [1, 6, 4]              [1, 5, 4]\n",
       "2           2   1  ...           [7, 8]                 [7, 5]\n",
       "3           3   1  ...           [7, 6]                 [7, 5]\n",
       "4           4   2  ...  [9, 10, 11, 12]  [9, 10, 5, 11, 13, 5]\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BRxWnvx6szFl",
    "outputId": "860a10f1-b063-4003-e3ab-a819b8a1fa3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5893, 300)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7hqzgqi_S3lh",
    "outputId": "b7d72b57-7b0a-4d3e-a587-0c06e5450eee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9992"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7BhSQOT3ld3e"
   },
   "outputs": [],
   "source": [
    "hold_out_test = train_df[train_df.id < 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "Z38ulZtfbaGT",
    "outputId": "2ced24c9-44fb-4417-edc7-49477b2da44a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>special</th>\n",
       "      <th>whole</th>\n",
       "      <th>label</th>\n",
       "      <th>masked</th>\n",
       "      <th>whole_bow</th>\n",
       "      <th>masked_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>orange juice</td>\n",
       "      <td>he pour orange juice on his cereal</td>\n",
       "      <td>0</td>\n",
       "      <td>he pour [MASK] on his cereal</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>[1, 5, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>milk</td>\n",
       "      <td>he pour milk on his cereal</td>\n",
       "      <td>1</td>\n",
       "      <td>he pour [MASK] on his cereal</td>\n",
       "      <td>[1, 6, 4]</td>\n",
       "      <td>[1, 5, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>he drink apple</td>\n",
       "      <td>0</td>\n",
       "      <td>he drink [MASK]</td>\n",
       "      <td>[7, 8]</td>\n",
       "      <td>[7, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>milk</td>\n",
       "      <td>he drink milk</td>\n",
       "      <td>1</td>\n",
       "      <td>he drink [MASK]</td>\n",
       "      <td>[7, 6]</td>\n",
       "      <td>[7, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>jeff run a mile today</td>\n",
       "      <td>1</td>\n",
       "      <td>jeff run [MASK] mile tod[MASK]y</td>\n",
       "      <td>[9, 10, 11, 12]</td>\n",
       "      <td>[9, 10, 5, 11, 13, 5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  ...        whole_bow             masked_bow\n",
       "0           0   0  ...     [1, 2, 3, 4]              [1, 5, 4]\n",
       "1           1   0  ...        [1, 6, 4]              [1, 5, 4]\n",
       "2           2   1  ...           [7, 8]                 [7, 5]\n",
       "3           3   1  ...           [7, 6]                 [7, 5]\n",
       "4           4   2  ...  [9, 10, 11, 12]  [9, 10, 5, 11, 13, 5]\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hold_out_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "lpj06zKPa9wI",
    "outputId": "0b607887-0fe0-428c-8a1f-0389fecc4684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n",
      "1539\n"
     ]
    }
   ],
   "source": [
    "for i in range(2000):\n",
    "    if i not in hold_out_test['id'].unique():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lezJFIImc-3-"
   },
   "outputs": [],
   "source": [
    "train_data = train_df[train_df.id >= 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuUf_WZv3LMA"
   },
   "outputs": [],
   "source": [
    "validation_size = int(len(train_data) * 0.2)\n",
    "training_size = len(train_data) - validation_size\n",
    "\n",
    "X = train_data[['whole_bow', 'masked_bow']]\n",
    "Y = train_data['label']\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "BzbMotc-dmFZ",
    "outputId": "61b45f8d-e52a-4cf4-ef86-9c3e0dda2e45"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whole_bow</th>\n",
       "      <th>masked_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8135</th>\n",
       "      <td>[185, 459, 2599, 166, 300, 3313]</td>\n",
       "      <td>[185, 459, 2599, 5, 166, 300, 3313]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20827</th>\n",
       "      <td>[3326, 2820, 136, 46, 529, 491]</td>\n",
       "      <td>[5, 2820, 136, 46, 529, 491]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13925</th>\n",
       "      <td>[1871, 404, 590, 363]</td>\n",
       "      <td>[1871, 5, 590, 363]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15980</th>\n",
       "      <td>[1342, 4767, 382]</td>\n",
       "      <td>[1342, 5, 382]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15908</th>\n",
       "      <td>[722, 299, 12]</td>\n",
       "      <td>[5, 299, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19722</th>\n",
       "      <td>[2978, 877, 67, 3907, 363]</td>\n",
       "      <td>[2978, 5, 67, 3907, 363]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9504</th>\n",
       "      <td>[928, 905]</td>\n",
       "      <td>[928, 5, 905]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6109</th>\n",
       "      <td>[166, 612, 64]</td>\n",
       "      <td>[166, 612, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11731</th>\n",
       "      <td>[1126, 3280, 1775, 988, 174]</td>\n",
       "      <td>[1126, 3280, 5, 988, 174]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6789</th>\n",
       "      <td>[167, 269, 3013]</td>\n",
       "      <td>[5, 269, 3013]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13780 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              whole_bow                           masked_bow\n",
       "8135   [185, 459, 2599, 166, 300, 3313]  [185, 459, 2599, 5, 166, 300, 3313]\n",
       "20827   [3326, 2820, 136, 46, 529, 491]         [5, 2820, 136, 46, 529, 491]\n",
       "13925             [1871, 404, 590, 363]                  [1871, 5, 590, 363]\n",
       "15980                 [1342, 4767, 382]                       [1342, 5, 382]\n",
       "15908                    [722, 299, 12]                         [5, 299, 12]\n",
       "...                                 ...                                  ...\n",
       "19722        [2978, 877, 67, 3907, 363]             [2978, 5, 67, 3907, 363]\n",
       "9504                         [928, 905]                        [928, 5, 905]\n",
       "6109                     [166, 612, 64]                        [166, 612, 5]\n",
       "11731      [1126, 3280, 1775, 988, 174]            [1126, 3280, 5, 988, 174]\n",
       "6789                   [167, 269, 3013]                       [5, 269, 3013]\n",
       "\n",
       "[13780 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QE86Xcm_2rh2"
   },
   "outputs": [],
   "source": [
    "def split_and_zero_padding(df, max_seq_length):\n",
    "    # Split to dicts\n",
    "    X = {'left': df['whole_bow'], 'right': df['masked_bow']}\n",
    "\n",
    "    # Zero padding\n",
    "    for dataset, side in itertools.product([X], ['left', 'right']):\n",
    "        dataset[side] = pad_sequences(dataset[side], padding='pre', truncating='post', maxlen=max_seq_length)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "#X_temp = {'left': X_train['whole_bow'], 'right': X_train['masked_bow']}\n",
    "#X_train['left'] = pad_sequences(X_temp['left'], padding='pre', truncating='post', maxlen=max_seq_length)\n",
    "#X_train['right'] = pad_sequences(X_temp['right'], padding='pre', truncating='post', maxlen=max_seq_length)\n",
    "\n",
    "class ManDist(Layer):\n",
    "    \"\"\"\n",
    "    Keras Custom Layer that calculates Manhattan Distance.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize the layer, No need to include inputs parameter!\n",
    "    def __init__(self, **kwargs):\n",
    "        self.result = None\n",
    "        super(ManDist, self).__init__(**kwargs)\n",
    "\n",
    "    # input_shape will automatic collect input shapes to build layer\n",
    "    def build(self, input_shape):\n",
    "        super(ManDist, self).build(input_shape)\n",
    "\n",
    "    # This is where the layer's logic lives.\n",
    "    def call(self, x, **kwargs):\n",
    "        self.result = K.exp(-K.sum(K.abs(x[0] - x[1]), axis=1, keepdims=True))\n",
    "        #self.result = K.pow(1+K.exp(-K.sum(K.abs(x[0] - x[1]), axis=1, keepdims=True)),-1)\n",
    "        return self.result\n",
    "\n",
    "    # return output shape\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return K.int_shape(self.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nXeKE_vEVaU-"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = split_and_zero_padding(X_train, max_seq_length)\n",
    "X_validation = split_and_zero_padding(X_validation, max_seq_length)\n",
    "\n",
    "Y_train = Y_train.values\n",
    "Y_validation = Y_validation.values\n",
    "\n",
    "# Make sure everything is ok\n",
    "assert X_train['left'].shape == X_train['right'].shape\n",
    "assert len(X_train['left']) == len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-D9N7twJYPaY",
    "outputId": "c265ca75-404e-4bec-c669-0cbb39586bb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 30)           1807620     input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "man_dist_1 (ManDist)            (None, 1)            0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,807,620\n",
      "Trainable params: 39,720\n",
      "Non-trainable params: 1,767,900\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20, 300)           1767900   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30)                39720     \n",
      "=================================================================\n",
      "Total params: 1,807,620\n",
      "Trainable params: 39,720\n",
      "Non-trainable params: 1,767,900\n",
      "_________________________________________________________________\n",
      "Train on 13780 samples, validate on 3445 samples\n",
      "Epoch 1/50\n",
      "13780/13780 [==============================] - 7s 533us/sample - loss: 0.2735 - acc: 0.4961 - val_loss: 0.2637 - val_acc: 0.4987\n",
      "Epoch 2/50\n",
      "13780/13780 [==============================] - 6s 456us/sample - loss: 0.2569 - acc: 0.5110 - val_loss: 0.2546 - val_acc: 0.5120\n",
      "Epoch 3/50\n",
      "13780/13780 [==============================] - 6s 454us/sample - loss: 0.2515 - acc: 0.5286 - val_loss: 0.2514 - val_acc: 0.5202\n",
      "Epoch 4/50\n",
      "13780/13780 [==============================] - 6s 459us/sample - loss: 0.2485 - acc: 0.5462 - val_loss: 0.2496 - val_acc: 0.5321\n",
      "Epoch 5/50\n",
      "13780/13780 [==============================] - 6s 457us/sample - loss: 0.2461 - acc: 0.5583 - val_loss: 0.2486 - val_acc: 0.5379\n",
      "Epoch 6/50\n",
      "13780/13780 [==============================] - 6s 462us/sample - loss: 0.2442 - acc: 0.5673 - val_loss: 0.2475 - val_acc: 0.5417\n",
      "Epoch 7/50\n",
      "13780/13780 [==============================] - 6s 460us/sample - loss: 0.2424 - acc: 0.5765 - val_loss: 0.2469 - val_acc: 0.5486\n",
      "Epoch 8/50\n",
      "13780/13780 [==============================] - 6s 456us/sample - loss: 0.2407 - acc: 0.5835 - val_loss: 0.2463 - val_acc: 0.5559\n",
      "Epoch 9/50\n",
      "13780/13780 [==============================] - 6s 460us/sample - loss: 0.2392 - acc: 0.5899 - val_loss: 0.2466 - val_acc: 0.5585\n",
      "Epoch 10/50\n",
      "13780/13780 [==============================] - 6s 456us/sample - loss: 0.2379 - acc: 0.5976 - val_loss: 0.2456 - val_acc: 0.5637\n",
      "Epoch 11/50\n",
      "13780/13780 [==============================] - 6s 457us/sample - loss: 0.2363 - acc: 0.5976 - val_loss: 0.2462 - val_acc: 0.5585\n",
      "Epoch 12/50\n",
      "13780/13780 [==============================] - 6s 453us/sample - loss: 0.2346 - acc: 0.6066 - val_loss: 0.2449 - val_acc: 0.5562\n",
      "Epoch 13/50\n",
      "13780/13780 [==============================] - 6s 460us/sample - loss: 0.2328 - acc: 0.6139 - val_loss: 0.2451 - val_acc: 0.5611\n",
      "Epoch 14/50\n",
      "13780/13780 [==============================] - 6s 455us/sample - loss: 0.2316 - acc: 0.6189 - val_loss: 0.2446 - val_acc: 0.5628\n",
      "Epoch 15/50\n",
      "13780/13780 [==============================] - 6s 461us/sample - loss: 0.2299 - acc: 0.6261 - val_loss: 0.2445 - val_acc: 0.5623\n",
      "Epoch 16/50\n",
      "13780/13780 [==============================] - 6s 459us/sample - loss: 0.2284 - acc: 0.6302 - val_loss: 0.2448 - val_acc: 0.5698\n",
      "Epoch 17/50\n",
      "13780/13780 [==============================] - 6s 456us/sample - loss: 0.2274 - acc: 0.6337 - val_loss: 0.2443 - val_acc: 0.5666\n",
      "Epoch 18/50\n",
      "13780/13780 [==============================] - 6s 462us/sample - loss: 0.2257 - acc: 0.6406 - val_loss: 0.2442 - val_acc: 0.5684\n",
      "Epoch 19/50\n",
      "13780/13780 [==============================] - 6s 455us/sample - loss: 0.2250 - acc: 0.6448 - val_loss: 0.2449 - val_acc: 0.5634\n",
      "Epoch 20/50\n",
      "13780/13780 [==============================] - 6s 455us/sample - loss: 0.2239 - acc: 0.6462 - val_loss: 0.2442 - val_acc: 0.5701\n",
      "Epoch 21/50\n",
      "13780/13780 [==============================] - 6s 457us/sample - loss: 0.2227 - acc: 0.6516 - val_loss: 0.2445 - val_acc: 0.5727\n",
      "Epoch 22/50\n",
      "13780/13780 [==============================] - 6s 451us/sample - loss: 0.2217 - acc: 0.6560 - val_loss: 0.2440 - val_acc: 0.5652\n",
      "Epoch 23/50\n",
      "13780/13780 [==============================] - 6s 454us/sample - loss: 0.2209 - acc: 0.6581 - val_loss: 0.2453 - val_acc: 0.5663\n",
      "Epoch 24/50\n",
      "13780/13780 [==============================] - 6s 455us/sample - loss: 0.2200 - acc: 0.6614 - val_loss: 0.2443 - val_acc: 0.5692\n",
      "Epoch 25/50\n",
      "13780/13780 [==============================] - 6s 465us/sample - loss: 0.2189 - acc: 0.6634 - val_loss: 0.2445 - val_acc: 0.5608\n",
      "Epoch 26/50\n",
      "13780/13780 [==============================] - 6s 455us/sample - loss: 0.2187 - acc: 0.6670 - val_loss: 0.2444 - val_acc: 0.5672\n",
      "Epoch 27/50\n",
      "13780/13780 [==============================] - 6s 455us/sample - loss: 0.2182 - acc: 0.6676 - val_loss: 0.2455 - val_acc: 0.5620\n",
      "Epoch 28/50\n",
      "13780/13780 [==============================] - 6s 458us/sample - loss: 0.2181 - acc: 0.6656 - val_loss: 0.2442 - val_acc: 0.5614\n",
      "Epoch 29/50\n",
      "13780/13780 [==============================] - 6s 456us/sample - loss: 0.2167 - acc: 0.6720 - val_loss: 0.2446 - val_acc: 0.5640\n",
      "Epoch 30/50\n",
      "13780/13780 [==============================] - 6s 454us/sample - loss: 0.2162 - acc: 0.6779 - val_loss: 0.2445 - val_acc: 0.5620\n",
      "Epoch 31/50\n",
      "13780/13780 [==============================] - 6s 451us/sample - loss: 0.2153 - acc: 0.6761 - val_loss: 0.2445 - val_acc: 0.5634\n",
      "Epoch 32/50\n",
      "13780/13780 [==============================] - 6s 455us/sample - loss: 0.2147 - acc: 0.6750 - val_loss: 0.2443 - val_acc: 0.5640\n",
      "Epoch 33/50\n",
      "13780/13780 [==============================] - 6s 452us/sample - loss: 0.2139 - acc: 0.6803 - val_loss: 0.2442 - val_acc: 0.5657\n",
      "Epoch 34/50\n",
      "13780/13780 [==============================] - 6s 460us/sample - loss: 0.2131 - acc: 0.6820 - val_loss: 0.2441 - val_acc: 0.5628\n",
      "Epoch 35/50\n",
      "13780/13780 [==============================] - 6s 459us/sample - loss: 0.2129 - acc: 0.6840 - val_loss: 0.2447 - val_acc: 0.5643\n",
      "Epoch 36/50\n",
      "13780/13780 [==============================] - 6s 462us/sample - loss: 0.2123 - acc: 0.6854 - val_loss: 0.2444 - val_acc: 0.5626\n",
      "Epoch 37/50\n",
      "13780/13780 [==============================] - 6s 467us/sample - loss: 0.2116 - acc: 0.6864 - val_loss: 0.2443 - val_acc: 0.5628\n",
      "Epoch 38/50\n",
      "13780/13780 [==============================] - 6s 457us/sample - loss: 0.2115 - acc: 0.6861 - val_loss: 0.2444 - val_acc: 0.5643\n",
      "Epoch 39/50\n",
      "13780/13780 [==============================] - 6s 454us/sample - loss: 0.2110 - acc: 0.6895 - val_loss: 0.2440 - val_acc: 0.5704\n",
      "Epoch 40/50\n",
      "13780/13780 [==============================] - 6s 458us/sample - loss: 0.2106 - acc: 0.6873 - val_loss: 0.2438 - val_acc: 0.5689\n",
      "Epoch 41/50\n",
      "13780/13780 [==============================] - 6s 454us/sample - loss: 0.2102 - acc: 0.6920 - val_loss: 0.2443 - val_acc: 0.5666\n",
      "Epoch 42/50\n",
      "13780/13780 [==============================] - 6s 454us/sample - loss: 0.2096 - acc: 0.6932 - val_loss: 0.2443 - val_acc: 0.5687\n",
      "Epoch 43/50\n",
      "13780/13780 [==============================] - 6s 459us/sample - loss: 0.2090 - acc: 0.6935 - val_loss: 0.2442 - val_acc: 0.5716\n",
      "Epoch 44/50\n",
      "13780/13780 [==============================] - 6s 462us/sample - loss: 0.2090 - acc: 0.6933 - val_loss: 0.2444 - val_acc: 0.5646\n",
      "Epoch 45/50\n",
      "13780/13780 [==============================] - 6s 461us/sample - loss: 0.2086 - acc: 0.6932 - val_loss: 0.2442 - val_acc: 0.5672\n",
      "Epoch 46/50\n",
      "13780/13780 [==============================] - 6s 457us/sample - loss: 0.2082 - acc: 0.6978 - val_loss: 0.2447 - val_acc: 0.5649\n",
      "Epoch 47/50\n",
      "13780/13780 [==============================] - 6s 466us/sample - loss: 0.2081 - acc: 0.6981 - val_loss: 0.2438 - val_acc: 0.5727\n",
      "Epoch 48/50\n",
      "13780/13780 [==============================] - 7s 475us/sample - loss: 0.2074 - acc: 0.6982 - val_loss: 0.2439 - val_acc: 0.5675\n",
      "Epoch 49/50\n",
      "13780/13780 [==============================] - 6s 462us/sample - loss: 0.2070 - acc: 0.6992 - val_loss: 0.2445 - val_acc: 0.5666\n",
      "Epoch 50/50\n",
      "13780/13780 [==============================] - 6s 460us/sample - loss: 0.2068 - acc: 0.7015 - val_loss: 0.2441 - val_acc: 0.5724\n",
      "Training time finished.\n",
      "50 epochs in       318.45\n",
      "0.5724(max: 0.5727)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# --\n",
    "\n",
    "# Model variables\n",
    "gpus = 1\n",
    "batch_size = 1024 * gpus\n",
    "n_epoch = 50\n",
    "n_hidden = 30\n",
    "\n",
    "# Define the shared model\n",
    "x = Sequential()\n",
    "x.add(Embedding(len(embeddings), embedding_dim,\n",
    "                weights=[embeddings], input_shape=(max_seq_length,), trainable=False))\n",
    "# CNN\n",
    "# x.add(Conv1D(250, kernel_size=5, activation='relu'))\n",
    "# x.add(GlobalMaxPool1D())\n",
    "# x.add(Dense(250, activation='relu'))\n",
    "# x.add(Dropout(0.3))\n",
    "# x.add(Dense(1, activation='sigmoid'))\n",
    "# LSTM\n",
    "x.add(LSTM(n_hidden))\n",
    "\n",
    "shared_model = x\n",
    "\n",
    "# The visible layer\n",
    "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "\n",
    "# Pack it all up into a Manhattan Distance model\n",
    "malstm_distance = ManDist()([shared_model(left_input), shared_model(right_input)])\n",
    "model = Model(inputs=[left_input, right_input], outputs=[malstm_distance])\n",
    "\n",
    "if gpus >= 2:\n",
    "    # `multi_gpu_model()` is a so quite buggy. it breaks the saved model.\n",
    "    model = tf.keras.utils.multi_gpu_model(model, gpus=gpus)\n",
    "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model.summary()\n",
    "shared_model.summary()\n",
    "\n",
    "# Start trainings\n",
    "training_start_time = time()\n",
    "malstm_trained = model.fit([X_train['left'], X_train['right']], Y_train,\n",
    "                           batch_size=batch_size, epochs=n_epoch,\n",
    "                           validation_data=([X_validation['left'], X_validation['right']], Y_validation))\n",
    "training_end_time = time()\n",
    "print(\"Training time finished.\\n%d epochs in %12.2f\" % (n_epoch,\n",
    "                                                        training_end_time - training_start_time))\n",
    "\n",
    "model.save('/content/SiameseLSTM.h5')\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(211)\n",
    "plt.plot(malstm_trained.history['acc'])\n",
    "plt.plot(malstm_trained.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(212)\n",
    "plt.plot(malstm_trained.history['loss'])\n",
    "plt.plot(malstm_trained.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "plt.tight_layout(h_pad=1.0)\n",
    "plt.savefig('/content/history-graph.png')\n",
    "\n",
    "print(str(malstm_trained.history['val_acc'][-1])[:6] +\n",
    "      \"(max: \" + str(max(malstm_trained.history['val_acc']))[:6] + \")\")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sy2nLKteiE64"
   },
   "outputs": [],
   "source": [
    "X_test = hold_out_test[['whole_bow', 'masked_bow']]\n",
    "Y_test = hold_out_test['label']\n",
    "\n",
    "X_test = split_and_zero_padding(X_test, max_seq_length)\n",
    "#X_validation = split_and_zero_padding(X_validation, max_seq_length)\n",
    "\n",
    "Y_test = Y_test.values\n",
    "#Y_validation = Y_validation.values\n",
    "\n",
    "# Make sure everything is ok\n",
    "assert X_test['left'].shape == X_test['right'].shape\n",
    "assert len(X_test['left']) == len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "colab_type": "code",
    "id": "j9UqLvPshiOw",
    "outputId": "94cddbb5-4901-461c-cea4-2fd06fb28b1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 30)           1807620     input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "man_dist_1 (ManDist)            (None, 1)            0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,807,620\n",
      "Trainable params: 39,720\n",
      "Non-trainable params: 1,767,900\n",
      "__________________________________________________________________________________________________\n",
      "[[0.6431845 ]\n",
      " [0.78090817]\n",
      " [0.42768618]\n",
      " ...\n",
      " [0.75174105]\n",
      " [0.4145894 ]\n",
      " [0.46319595]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('/content/SiameseLSTM.h5', custom_objects={'ManDist': ManDist})\n",
    "model.summary()\n",
    "\n",
    "prediction = model.predict([X_test['left'], X_test['right']])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GZFEHYPaiHpE",
    "outputId": "8b9dcbb0-b171-421f-ea46-555f1d523cbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4424, 20)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['left'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zcVhvSJ3iT-v",
    "outputId": "ea073f17-2344-4a4b-c872-df3e3dc66d91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4424"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test['left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Kh7BkZ4ZiWzR",
    "outputId": "bc8b9044-6a95-4281-8c57-0734b085eb1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4424"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "331eiSfyicBB",
    "outputId": "a28a4b60-17ea-4dcf-8256-79b74b9aadda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4424"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hold_out_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "c5IF6nFDhwOG",
    "outputId": "a6701dcb-dd01-46ee-cd04-2a7b8bb988af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "hold_out_test['predicted_label'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "X9MD0Zwgh5XM",
    "outputId": "a2ff88d1-f754-445b-e0cb-1478f93325c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>special</th>\n",
       "      <th>whole</th>\n",
       "      <th>label</th>\n",
       "      <th>masked</th>\n",
       "      <th>whole_bow</th>\n",
       "      <th>masked_bow</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>walk in</td>\n",
       "      <td>a walk in closet be large than a normal closet</td>\n",
       "      <td>1</td>\n",
       "      <td>a [MASK] closet be large than a normal closet</td>\n",
       "      <td>[19, 20, 21, 22, 20]</td>\n",
       "      <td>[5, 20, 21, 22, 20]</td>\n",
       "      <td>0.594448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>normal</td>\n",
       "      <td>a walk in closet be large than a normal closet</td>\n",
       "      <td>1</td>\n",
       "      <td>a walk in closet be large than a [MASK] closet</td>\n",
       "      <td>[19, 20, 21, 22, 20]</td>\n",
       "      <td>[19, 20, 21, 5, 20]</td>\n",
       "      <td>0.331226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>normal</td>\n",
       "      <td>a normal closet be large than a walk in closet</td>\n",
       "      <td>0</td>\n",
       "      <td>a [MASK] closet be large than a walk in closet</td>\n",
       "      <td>[22, 20, 21, 19, 20]</td>\n",
       "      <td>[5, 20, 21, 19, 20]</td>\n",
       "      <td>0.318269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>walk in</td>\n",
       "      <td>a normal closet be large than a walk in closet</td>\n",
       "      <td>0</td>\n",
       "      <td>a normal closet be large than a [MASK] closet</td>\n",
       "      <td>[22, 20, 21, 19, 20]</td>\n",
       "      <td>[22, 20, 21, 5, 20]</td>\n",
       "      <td>0.514080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  id  ...           masked_bow predicted_label\n",
       "10          10   5  ...  [5, 20, 21, 22, 20]        0.594448\n",
       "11          11   5  ...  [19, 20, 21, 5, 20]        0.331226\n",
       "12          12   5  ...  [5, 20, 21, 19, 20]        0.318269\n",
       "13          13   5  ...  [22, 20, 21, 5, 20]        0.514080\n",
       "\n",
       "[4 rows x 9 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hold_out_test[hold_out_test['id']==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FrE8DBAFkzug",
    "outputId": "75bd625a-f969-4827-f957-43ed011fab41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.462837"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.594448+0.331226)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NFBT809mk6hP",
    "outputId": "80acd0c8-2a4e-464c-cb7b-82a1e571b4fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4161745"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.514080+0.318269)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LhzWxUNAlSbw"
   },
   "outputs": [],
   "source": [
    "try_data = hold_out_test[hold_out_test.id.values == 5]\n",
    "score_1 = try_data.predicted_label[try_data[\"label\"]==1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "u77lfj6ElUVN",
    "outputId": "46ef6217-eec4-4f4e-f989-a18d60b03f87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46283728"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(score_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "yiAIZxKNh-ip",
    "outputId": "d56bbb0c-3be3-46b6-cadc-c225ec15fc11"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "predict_result = {}\n",
    "for i in range(0,2000): \n",
    "    #if i in hold_out_test['id'].unique():\n",
    "        try_data = hold_out_test[hold_out_test.id.values == i]\n",
    "        score_1 = np.mean(try_data.predicted_label[try_data[\"label\"]==1].values)\n",
    "        score_0 = np.mean(try_data.predicted_label[try_data[\"label\"]==0].values)\n",
    "        score = [score_0,score_1]\n",
    "        #predicted_result_label = score.index(max(score))\n",
    "        predict_result[i] = score.index(max(score))\n",
    "    #else:\n",
    "       # predict_result[i] = \"NA\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "i2k6zXSHh8NC",
    "outputId": "a15bab61-3bbd-4402-d1ea-b25882b53881"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6656656656656657"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predict_result.values())/1998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tghfg3K6mfdW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MA-LSTM using ConceptNet embeddings",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
