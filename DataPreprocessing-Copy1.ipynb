{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('Training  Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('subtaskA_answers_all.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('subtaskA_data_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sent0</th>\n",
       "      <th>sent1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>He poured orange juice on his cereal.</td>\n",
       "      <td>He poured milk on his cereal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>He drinks apple.</td>\n",
       "      <td>He drinks milk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jeff ran a mile today</td>\n",
       "      <td>Jeff ran 100,000 miles today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A mosquito stings me</td>\n",
       "      <td>I sting a mosquito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A niece is a person.</td>\n",
       "      <td>A giraffe is a person.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                  sent0                          sent1\n",
       "0   0  He poured orange juice on his cereal.  He poured milk on his cereal.\n",
       "1   1                       He drinks apple.                He drinks milk.\n",
       "2   2                  Jeff ran a mile today   Jeff ran 100,000 miles today\n",
       "3   3                   A mosquito stings me             I sting a mosquito\n",
       "4   4                   A niece is a person.         A giraffe is a person."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "from nltk.corpus import wordnet as wn\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def convert_plural_tense(sent):\n",
    "    text = sent.replace('-','_')\n",
    "    text = text.lower()\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    \n",
    "    wnl = nltk.WordNetLemmatizer()    \n",
    "    output = []\n",
    "    # if known pos tag\n",
    "    #ls = [('running', 'n'), ('helping', 'n'), ('cooks', 'n'), ('finds','n')]\n",
    "    #output = [wnl.lemmatize(word, pos) for word, pos in ls]\n",
    "    for w in text:\n",
    "        syn = wn.synsets(w)\n",
    "        if len(syn):\n",
    "            pos = syn[0].pos()\n",
    "            output.append(wnl.lemmatize(w, pos))\n",
    "        else:\n",
    "            output.append(wnl.lemmatize(w))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    text = sent.replace('-','_')\n",
    "    text = text.lower()\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def tokenizer(sent1, sent2):\n",
    "    li1 = [tk.text for tk in sent1]\n",
    "    li2 = [tk.text for tk in sent2]\n",
    "    #dif21 = [i for i in li1 + li2 if i not in li1] \n",
    "    #dif12 = [i for i in li1 + li2 if i not in li2] \n",
    "    (dif12, dif21), (masked1, masked2) = my_get_opcodes(li1,li2)\n",
    "    #print(dif12)\n",
    "    #print(dif21)\n",
    "    spe1 = []\n",
    "    spe2 = []\n",
    "    #print(sent1.text)\n",
    "    #print(sent2.text)\n",
    "    #print(dif12)\n",
    "    get_special_word_list(sent1.text, dif12, [], spe1, 1)\n",
    "    get_special_word_list(sent2.text, dif21, [], spe2, 1)\n",
    "    return spe1, spe2, \" \".join(masked1), \" \".join(masked2)\n",
    "\n",
    "def my_get_opcodes(a, b):\n",
    "    output = [[],[]]\n",
    "    masked_output = [[],[]]\n",
    "    #print(a, b)\n",
    "    s = SequenceMatcher(None, a, b)\n",
    "    for tag, i1, i2, j1, j2 in s.get_opcodes():\n",
    "        #print('{:7}   a[{}:{}] --> b[{}:{}] {!r:>8} --> {!r}'.format(tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2]))\n",
    "        if tag!='equal':\n",
    "            output[0]+=a[i1:i2]\n",
    "            output[1]+=b[j1:j2]\n",
    "            #masked_output[0]+=['[MASK]']\n",
    "            #masked_output[1]+=['[MASK]']\n",
    "        #else:\n",
    "            #masked_output[0]+=a[i1:i2]\n",
    "            #masked_output[1]+=b[j1:j2]\n",
    "    return output, masked_output\n",
    "\n",
    "\n",
    "def get_special_word_list(sent, dif_a, dif_b, spe, lv):\n",
    "    #print('-----------------',lv,'----------------')\n",
    "    if not dif_a:\n",
    "        return False\n",
    "    if \" \".join(dif_a) in sent:\n",
    "        #print(lv,'dif_a',dif_a, 'dif_b',dif_b)\n",
    "        spe.append(\" \".join(dif_a))\n",
    "        dif_a.clear()\n",
    "        #print(dif_a)\n",
    "    else:\n",
    "        #print('not found', lv, dif_a, dif_b)\n",
    "        dif_a_n = dif_a[:-1]\n",
    "        dif_b_n = dif_a[-1:]+dif_b\n",
    "        dif_a = dif_a_n\n",
    "        dif_b = dif_b_n\n",
    "        finished = get_special_word_list(sent, dif_a, dif_b, spe,lv+1)\n",
    "        #print('- A',finished)        \n",
    "        #print('***spe***',lv, spe, dif_a, dif_b)\n",
    "        if finished:\n",
    "            dif_a.clear()\n",
    "            dif_b.clear()\n",
    "\n",
    "        finished = get_special_word_list(sent, dif_b, [], spe,lv+1)\n",
    "        if finished:\n",
    "            dif_a.clear()\n",
    "            dif_b.clear()\n",
    "        #print('-- B', finished)\n",
    "        #print('***spe***',lv, spe, dif_a, dif_b)\n",
    "        if dif_b == []:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(new_sent0, new_sent1):\n",
    "    output = []\n",
    "    for i, (sent0, sent1) in enumerate(zip(new_sent0, new_sent1)):\n",
    "        spec0, spec1, mask1, mask2 = tokenizer(nlp(sent0),nlp(sent1))\n",
    "        gt = labels[i]\n",
    "        if labels[i] == 0:\n",
    "            for spec in spec0:\n",
    "                output.append({'id':i, 'special':spec,'whole':sent0,'label':0, 'masked':mask1})\n",
    "            for spec in spec1:\n",
    "                output.append({'id':i, 'special':spec,'whole':sent1,'label':1,'masked':mask2})\n",
    "        else:\n",
    "            for spec in spec0:\n",
    "                output.append({'id':i, 'special':spec,'whole':sent0,'label':1, 'masked': mask1})\n",
    "            for spec in spec1:\n",
    "                output.append({'id':i, 'special':spec,'whole':sent1,'label':0, 'masked':mask2})\n",
    "    return pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample0 = data['sent0'].values\n",
    "sample1 = data['sent1'].values\n",
    "new_sent0 = [\" \".join(convert_plural_tense(s)) for s in sample0]\n",
    "new_sent1 = [\" \".join(convert_plural_tense(s)) for s in sample1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = prepare_data(new_sent0, new_sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('train_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n",
      "1539\n",
      "4075\n",
      "4121\n",
      "4313\n",
      "6398\n",
      "7700\n",
      "9622\n"
     ]
    }
   ],
   "source": [
    "for idx in range(10000):\n",
    "    if idx not in df_train['id'].unique():\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9992"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train['masked'] = np.array(len(df_train),dtype='str')\n",
    "for i, row in df_train.iterrows():\n",
    "    masked = row['whole'].replace(' '+row['special'], ' [MASK] ')\n",
    "    df_train.at[i, 'masked'] = masked\n",
    "df_train.to_csv('train_masked_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sent0</th>\n",
       "      <th>sent1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>248</td>\n",
       "      <td>Potatos is the plural of potato</td>\n",
       "      <td>Potatoes is the plural of potato</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                            sent0                             sent1\n",
       "248  248  Potatos is the plural of potato  Potatoes is the plural of potato"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['id']==248]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>special</th>\n",
       "      <th>whole</th>\n",
       "      <th>label</th>\n",
       "      <th>masked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, special, whole, label, masked]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[df_train['id']==248]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9995"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['masked'] = np.array(len(df_train),dtype='str')\n",
    "for i, row in df_train.iterrows():\n",
    "    masked = row['whole'].replace(' '+row['special'], ' [MASK]')\n",
    "    df_train.at[i, 'masked'] = masked\n",
    "df_train.to_csv('train_masked_no_lemma.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>special</th>\n",
       "      <th>whole</th>\n",
       "      <th>label</th>\n",
       "      <th>masked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>orange juice</td>\n",
       "      <td>he poured orange juice on his cereal</td>\n",
       "      <td>0</td>\n",
       "      <td>he poured [MASK] on his cereal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>milk</td>\n",
       "      <td>he poured milk on his cereal</td>\n",
       "      <td>1</td>\n",
       "      <td>he poured [MASK] on his cereal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>he drinks apple</td>\n",
       "      <td>0</td>\n",
       "      <td>he drinks [MASK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>milk</td>\n",
       "      <td>he drinks milk</td>\n",
       "      <td>1</td>\n",
       "      <td>he drinks [MASK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>a mile</td>\n",
       "      <td>jeff ran a mile today</td>\n",
       "      <td>1</td>\n",
       "      <td>jeff ran [MASK] today</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       special                                 whole  label  \\\n",
       "0   0  orange juice  he poured orange juice on his cereal      0   \n",
       "1   0          milk          he poured milk on his cereal      1   \n",
       "2   1         apple                       he drinks apple      0   \n",
       "3   1          milk                        he drinks milk      1   \n",
       "4   2        a mile                 jeff ran a mile today      1   \n",
       "\n",
       "                           masked  \n",
       "0  he poured [MASK] on his cereal  \n",
       "1  he poured [MASK] on his cereal  \n",
       "2                he drinks [MASK]  \n",
       "3                he drinks [MASK]  \n",
       "4           jeff ran [MASK] today  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
